{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "initialization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maxarreaga/APS360/blob/main/init.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jibuAp-jC7te"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIdyzH5JHhBW"
      },
      "source": [
        "## This is the initilization for our APS360 Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU0EGh0oW_al"
      },
      "source": [
        "# Imports\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random \n",
        "import math \n",
        "import cv2 \n",
        "import os \n",
        "import shutil\n",
        "import pathlib\n",
        "from google.colab import files\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VMR9U379MF2"
      },
      "source": [
        "!mkdir -p root/.kaggle/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36gCvKnDGbGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0312033-fa3b-4c4d-f204-4afec9ba2004"
      },
      "source": [
        "!pip install ray\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.9.0-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.42.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.4.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.0.2-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->redis>=3.5.0->ray) (1.13.3)\n",
            "Installing collected packages: deprecated, redis, ray\n",
            "Successfully installed deprecated-1.2.13 ray-1.9.0 redis-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Y8bSv2FLxj",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "1250f3ff-5671-4002-cea6-5aed16f8cbba"
      },
      "source": [
        "def get_kaggle_data():\n",
        "  print('Upload Kaggle api token :')\n",
        "  files.upload()\n",
        "  !pip install -q kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !ls ~/.kaggle\n",
        "  !chmod 600 /root/.kaggle/kaggle.json \n",
        "\n",
        "  !kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "  !unzip -q /content/gtsrb-german-traffic-sign.zip -d Data\n",
        "\n",
        "get_kaggle_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Kaggle api token :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc4c0a56-4708-496d-8600-c91ec3a9cd11\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dc4c0a56-4708-496d-8600-c91ec3a9cd11\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "kaggle.json\n",
            "Downloading gtsrb-german-traffic-sign.zip to /content\n",
            " 99% 607M/612M [00:07<00:00, 86.8MB/s]\n",
            "100% 612M/612M [00:08<00:00, 80.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbhw4knFMhE"
      },
      "source": [
        "tran = transforms.Compose([transforms.Resize((32,32)),\n",
        "                           transforms.Grayscale(),\n",
        "                           transforms.RandomAffine(degrees=20,translate=(0,0.1),scale=(1,1.2)),\n",
        "                           #transforms.Normalize((0.5,),(0.5,)),\n",
        "                           transforms.ToTensor()\n",
        "                           ])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFqUvSwoFPH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575f050f-d047-4631-c453-9002a819eef4"
      },
      "source": [
        "image_datasets = torchvision.datasets.ImageFolder('/content/Data/Train', transform=tran)\n",
        "\n",
        "num_images = len(image_datasets)\n",
        "train_split_val = round(num_images*0.60)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(image_datasets,[train_split_val,num_images-train_split_val])\n",
        "\n",
        "num_val_images = len(val_set)\n",
        "test_split_val = round(num_val_images*0.5)\n",
        "\n",
        "val_set, test_set = torch.utils.data.random_split(val_set,[test_split_val,num_val_images-test_split_val])\n",
        "print('Train Set: ', len(train_set))\n",
        "print('Validation Set: ', len(val_set))\n",
        "print('Test Set: ', len(test_set))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set:  23525\n",
            "Validation Set:  7842\n",
            "Test Set:  7842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXkO8FEkxHWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45eb3784-097d-4844-d906-61e22f17e8b6"
      },
      "source": [
        "# Pytorch assigns its own numbers as labels so they dont match up with the folder number names in the dataset\n",
        "# This part is needed to interpret the prediction\n",
        "dict((int(i),int(l)) for l,i in image_datasets.class_to_idx.items())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0,\n",
              " 1: 1,\n",
              " 2: 10,\n",
              " 3: 11,\n",
              " 4: 12,\n",
              " 5: 13,\n",
              " 6: 14,\n",
              " 7: 15,\n",
              " 8: 16,\n",
              " 9: 17,\n",
              " 10: 18,\n",
              " 11: 19,\n",
              " 12: 2,\n",
              " 13: 20,\n",
              " 14: 21,\n",
              " 15: 22,\n",
              " 16: 23,\n",
              " 17: 24,\n",
              " 18: 25,\n",
              " 19: 26,\n",
              " 20: 27,\n",
              " 21: 28,\n",
              " 22: 29,\n",
              " 23: 3,\n",
              " 24: 30,\n",
              " 25: 31,\n",
              " 26: 32,\n",
              " 27: 33,\n",
              " 28: 34,\n",
              " 29: 35,\n",
              " 30: 36,\n",
              " 31: 37,\n",
              " 32: 38,\n",
              " 33: 39,\n",
              " 34: 4,\n",
              " 35: 40,\n",
              " 36: 41,\n",
              " 37: 42,\n",
              " 38: 5,\n",
              " 39: 6,\n",
              " 40: 7,\n",
              " 41: 8,\n",
              " 42: 9}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHf2Hk3rEIUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cf6902-43d3-4e84-9fd6-8b9271571fc6"
      },
      "source": [
        "# Creating DataLoader \n",
        "batch_size = 100\n",
        "num_workers = 1\n",
        "print(\"trainSet Columns = {}\", train_set)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainSet Columns = {} <torch.utils.data.dataset.Subset object at 0x7f310d899dd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKukNSryjLQs"
      },
      "source": [
        "def get_accuracy(model, data, device):\n",
        "    \"\"\" Compute the accuracy of the `model` across a dataset `data`\n",
        "    \"\"\"\n",
        "\n",
        "    # From tutorial\n",
        "    correct,total = 0, 0\n",
        "    for img, labels in data:\n",
        "      img, labels = img.to(device), labels.to(device)\n",
        "      result = model(img)\n",
        "      pred = result.max(1,keepdim=True)[1]\n",
        "      correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "      total += labels.shape[0]\n",
        "    accuracy = correct/total\n",
        "    return accuracy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-KxzlCNG6JT"
      },
      "source": [
        "# \n",
        "class GTSRBClassifier(nn.Module):\n",
        "  def __init__(self, conv1Channels = 32, conv2Channels = 64, features = 64):\n",
        "    self.name = \"GTSRBClassifier\"\n",
        "    super(GTSRBClassifier,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,conv1Channels,3) #format is in (1 if greyscale 3 if rgb),out channel third number, kernel\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(conv1Channels,conv2Channels,3)\n",
        "    self.conv3 = nn.Conv2d(conv2Channels,128,3)\n",
        "    self.fc1 = nn.Linear(2*2*128,features)\n",
        "    self.fc2 = nn.Linear(features,43)\n",
        "\n",
        "  def forward(self,image):\n",
        "    image = self.pool(F.relu(self.conv1(image)))\n",
        "    image = self.pool(F.relu(self.conv2(image)))\n",
        "    x = self.pool(F.relu(self.conv3(image)))\n",
        "    #print(\"shape x= {}\",x.shape)\n",
        "    x = x.view(x.size(0), -1) #flattening\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = x.squeeze(1)\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5pwuAzpUjzx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ViW2SRfclEI"
      },
      "source": [
        "# Curve Plotting\n",
        "def plotCurve(xData,yData,lineLabel,loss=False):\n",
        "  plt.plot(xData,yData,label=lineLabel)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  if(loss==True):\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Epochs vs Loss\")\n",
        "  else:\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Epochs vs Accuracy\")\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "def train(model, train_loader, valid_loader,batch_size=64, num_epochs=5, learning_rate=1e-4,plot=True):\n",
        "    \n",
        "    # allow parallel processing using cuda GPU if available\n",
        "    dev = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"cuda available, sending data to GPU\")\n",
        "        dev = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "\n",
        "    device = torch.device(dev)  \n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # set up  \n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Creation of arrays for data recording\n",
        "    trainingLosses = []\n",
        "    validationLosses = []\n",
        "    trainingAccuracy = []\n",
        "    validationAccuracy = []\n",
        "    iterations = []\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train Loop\n",
        "        print(\"entered training\")\n",
        "        for data,labels  in train_loader:\n",
        "            #send to cuda GPU if available\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            #datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "            recon = model(data)\n",
        "            loss = criterion(recon, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        trainingLosses.append(loss)\n",
        "        trainAccuracy = get_accuracy(model,train_loader,device)\n",
        "        trainingAccuracy.append(trainAccuracy)\n",
        "        iterations.append(epoch)\n",
        "\n",
        "        # get validation data\n",
        "        print(\"exited training\")\n",
        "        #Validation loop\n",
        "        print(\"entered validation\")\n",
        "\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for data,labels in valid_loader:\n",
        "          #send to cuda GPU if available\n",
        "          data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "          #datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "          recon = model(data)\n",
        "          validationLoss = criterion(recon, labels)\n",
        "          val_loss = validationLoss.detach().numpy()\n",
        "          val_steps += 1\n",
        "        validationLosses.append(validationLoss)\n",
        "        validAcc = get_accuracy(model,valid_loader,device)\n",
        "        validationAccuracy.append(validAcc)\n",
        "        if tune.is_session_enabled():\n",
        "          tune.report(loss=val_loss, accuracy=validAcc)\n",
        "        print(\"Epoch {} ended\".format(epoch))\n",
        "        print(\"current Training Loss {}, current validation Loss {} \".format(loss,validationLoss))\n",
        "        print(\"current Training Accuracy {}, current validation Accuracy {} \".format(trainAccuracy,validAcc))\n",
        "        PATH = \"model_{}batchSize{}LearningRate{}Epoch{}\".format(model.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "\n",
        "    #Plotting results\n",
        "    if(plot == True):\n",
        "        plotCurve(xData=iterations,yData=trainingLosses,lineLabel=\"Training\",loss=True)\n",
        "        plotCurve(xData=iterations,yData=validationLosses,lineLabel=\"Validation\",loss=True)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "          \n",
        "        plotCurve(xData=iterations,yData=trainingAccuracy,lineLabel=\"Training\",loss=False)\n",
        "        plotCurve(xData=iterations,yData=validationAccuracy,lineLabel=\"Validation\",loss=False)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"Final training accuracy: {} \\n final validation accuracy: {} \\n final training loss: {} \\n final validation loss: {}\".format(trainAccuracy,validAcc,loss,validationLoss))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbiVgHsexIB-"
      },
      "source": [
        "def test(model, test_loader):\n",
        "\n",
        "  # allow parallel processing using cuda GPU if available\n",
        "  dev = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "      print(\"cuda available, sending data to GPU\")\n",
        "      dev = \"cuda:0\"\n",
        "      if torch.cuda.device_count() > 1:\n",
        "          model = nn.DataParallel(model)\n",
        "\n",
        "  device = torch.device(dev)  \n",
        "  model.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  #Validation loop\n",
        "  print(\"entered test\")\n",
        "\n",
        "  val_loss = 0.0\n",
        "  val_steps = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for data,labels in test_loader:\n",
        "\n",
        "    #send to cuda GPU if available\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    #datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n",
        "    recon = model(data)\n",
        "    testLoss = criterion(recon, labels)\n",
        "    val_loss = testLoss.detach().numpy()\n",
        "    val_steps += 1\n",
        "\n",
        "  testAcc = get_accuracy(model,test_loader,device)\n",
        "  \n",
        "  print(\"current test Loss {} \".format(testLoss))\n",
        "  print(\"current test Accuracy {} \".format(testAcc))\n",
        "  print(\"exit test\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25saP3Ax5i7t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "57d8bff8-22ca-495d-a7e2-2c36e101cade"
      },
      "source": [
        "# Exports Model for download for real time use\n",
        "x = torch.randn(1,1,32,32)\n",
        "torch_out= model(x)\n",
        "onnx_model_path = \"SignDetector.onnx\"\n",
        "torch.onnx.export(model,x,\"SignDetector.onnx\",export_params=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8d4e3d07f6b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Exports Model for download for real time use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch_out\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0monnx_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SignDetector.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SignDetector.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rUN5vKwOYu6"
      },
      "source": [
        "config = {\n",
        "    \"c1\": tune.sample_from(lambda _: np.random.randint(75, 130)),\n",
        "    \"c2\": tune.sample_from(lambda _: np.random.randint(50, 145)),\n",
        "    \"f1\": tune.sample_from(lambda _: np.random.randint(50, 150)),\n",
        "    \"lr\": tune.loguniform(8e-4, 4e-3),\n",
        "    \"num_epochs\": tune.sample_from(lambda _: np.random.randint(20, 26)),\n",
        "    \"batch_size\": tune.choice([256, 350, 512, 800, 1024, 1600, 2048])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdjDvS9mSBsX"
      },
      "source": [
        "def HyperTuning(config, train_loader, valid_loader):\n",
        "  model = GTSRBClassifier(config[\"c1\"],config[\"c2\"],config[\"f1\"])\n",
        "  train(model, train_loader, valid_loader, batch_size=config[\"batch_size\"], num_epochs=config[\"num_epochs\"], learning_rate=config[\"lr\"], plot=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oLmqQmxZMT-"
      },
      "source": [
        "# Run this for Random Search Hyper Parameter based on Config Dictionary. (Approx 7-8 hours to complete)\n",
        "# If you want to run one model skip this block and run the next\n",
        "smoke_test = False\n",
        "scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\")\n",
        "reporter = CLIReporter(\n",
        "        metric_columns=[\"loss\", \"accuracy\"])\n",
        "result = tune.run(partial(HyperTuning, train_loader=train_loader, valid_loader=val_loader),\n",
        "                  config=config,\n",
        "                  scheduler = scheduler,\n",
        "                  num_samples = 5 if smoke_test else 20,\n",
        "                  progress_reporter = reporter,\n",
        "                  resources_per_trial={\"cpu\": 2, \"gpu\": 0})\n",
        "configlist = result.get_all_configs()\n",
        "btrial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "print(configlist)\n",
        "print(\"Best config: \", btrial.config)\n",
        "print(\"Best trial loss: \", btrial.last_result[\"loss\"])\n",
        "print(\"Best trial accuracy: \", btrial.last_result[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPGh45sUQyfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16afb3e6-d3a6-48d9-d23d-a761f144c701"
      },
      "source": [
        "#running the actual loop on current best parameters\n",
        "model = GTSRBClassifier(conv1Channels=83, conv2Channels=94, features=147)\n",
        "batch_size = 800\n",
        "epochs = 24\n",
        "learningRate = 0.000922458\n",
        "#print(type(train_loader))\n",
        "train(model=model,train_loader=train_loader,valid_loader=val_loader,batch_size=batch_size,num_epochs=epochs,learning_rate=learningRate,plot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 0 ended\n",
            "current Training Loss 3.1817831993103027, current validation Loss 3.2414634227752686 \n",
            "current Training Accuracy 0.11370882040382571, current validation Accuracy 0.11476664116296863 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 1 ended\n",
            "current Training Loss 1.9645391702651978, current validation Loss 1.74770188331604 \n",
            "current Training Accuracy 0.5143889479277365, current validation Accuracy 0.5075235909206836 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 2 ended\n",
            "current Training Loss 1.0421850681304932, current validation Loss 1.696604609489441 \n",
            "current Training Accuracy 0.6715834218916047, current validation Accuracy 0.6689619994899261 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 3 ended\n",
            "current Training Loss 0.8487601280212402, current validation Loss 0.9449424743652344 \n",
            "current Training Accuracy 0.7580021253985122, current validation Accuracy 0.7492986483040041 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 4 ended\n",
            "current Training Loss 0.38490524888038635, current validation Loss 0.8106572031974792 \n",
            "current Training Accuracy 0.8259723698193411, current validation Accuracy 0.8085947462382045 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 5 ended\n",
            "current Training Loss 0.3742370307445526, current validation Loss 0.7202885150909424 \n",
            "current Training Accuracy 0.8353241232731137, current validation Accuracy 0.8283601122162714 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 6 ended\n",
            "current Training Loss 0.3842121958732605, current validation Loss 0.6822936534881592 \n",
            "current Training Accuracy 0.8691604675876727, current validation Accuracy 0.8574343279775567 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 7 ended\n",
            "current Training Loss 0.2378053516149521, current validation Loss 0.35372182726860046 \n",
            "current Training Accuracy 0.8755366631243359, current validation Accuracy 0.866360622290232 \n",
            "entered training\n",
            "exited training\n",
            "entered validation\n",
            "Epoch 8 ended\n",
            "current Training Loss 0.08421104401350021, current validation Loss 0.25660669803619385 \n",
            "current Training Accuracy 0.9100531349628055, current validation Accuracy 0.8941596531497067 \n",
            "entered training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2aly0ewxW9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c05ec-8702-4b1b-d6bc-525e186a3383"
      },
      "source": [
        "test(model=model, test_loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered test\n",
            "current test Loss 0.008387191221117973 \n",
            "current test Accuracy 0.9794945038129002 \n",
            "exit test\n"
          ]
        }
      ]
    }
  ]
}